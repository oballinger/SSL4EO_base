{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57159f61-bca0-4e79-8b76-3cefb4ddde37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/project/cenv/ssl4eo/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.utils.data as tdata\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# loading python packages and files from repo root\n",
    "if Path(os.getcwd()).name != \"SSL4EO_base\":\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "from main import METHODS\n",
    "from data import constants, GeobenchDataset\n",
    "from data.constants import MMEARTH_DIR, input_size\n",
    "from data.mmearth_dataset import MMEarthDataset, create_MMEearth_args, get_mmearth_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "085eb42d-d5a5-47b6-9709-489aa56d6f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_model(model_path, method, device):\n",
    "\n",
    "    model_ckpt = torch.load(model_path, map_location=device) # no gpu required for running small samples\n",
    "\n",
    "    # intialize model from checkpoint hyper parameters\n",
    "    hparams = model_ckpt[\"hyper_parameters\"]\n",
    "    model = METHODS[method][\"model\"](\n",
    "        backbone=hparams[\"backbone\"], \n",
    "        batch_size_per_device=hparams[\"batch_size_per_device\"], \n",
    "        in_channels=hparams[\"in_channels\"], \n",
    "        num_classes=hparams[\"num_classes\"], \n",
    "        has_online_classifier=hparams[\"has_online_classifier\"], \n",
    "        last_backbone_channel=hparams[\"last_backbone_channel\"], \n",
    "        train_transform=METHODS[method][\"transform\"]\n",
    "    )\n",
    "\n",
    "    # Load weights\n",
    "    model.load_state_dict(model_ckpt[\"state_dict\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def get_layer_from_name(model, layer_name):\n",
    "    layer = model\n",
    "    for name in layer_name.split('.'):\n",
    "        if name.isdigit():\n",
    "            layer = layer[int(name)]\n",
    "        else:\n",
    "            layer = layer.__getattr__(name)\n",
    "    return layer\n",
    "    \n",
    "class Model2Embeddings:\n",
    "\n",
    "    def __init__(self, model, layers_to_save, flatten_output=True):\n",
    "\n",
    "        self.model = model\n",
    "        self.layers_to_save = layers_to_save\n",
    "        self.flatten_output = flatten_output\n",
    "        if flatten_output:\n",
    "            self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.d_embeddings = {}\n",
    "        for layer_to_save in layers_to_save:\n",
    "            self.register_forward_hook(model, layer_to_save)\n",
    "        print('Forward hooks registered')\n",
    "\n",
    "    def get_activation(self, name):\n",
    "        def hook(model, input, output):\n",
    "            if self.flatten_output:\n",
    "                self.d_embeddings[name] = self.global_pool(output.detach().cpu()).squeeze().numpy()\n",
    "            else:\n",
    "                self.d_embeddings[name] = output.detach().cpu().squeeze().numpy()\n",
    "        return hook\n",
    "\n",
    "    def register_forward_hook(self, model, layer_name):\n",
    "        layer = get_layer_from_name(model, layer_name)\n",
    "        layer.register_forward_hook(self.get_activation(layer_name))\n",
    "\n",
    "    def forward_pass(self, data):\n",
    "        self.model(data)\n",
    "        return self.d_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f05784a8-05df-4712-b3a7-6fd7f18036ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings_geobench(model_path, method, dataset_name, layers_to_save, base_output_dir=None):\n",
    "\n",
    "    print(f'Creating embeddings for {len(layers_to_save)} layers with {method} and {dataset_name}.')\n",
    "          \n",
    "    # Load pre-trained model\n",
    "    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    model = get_pretrained_model(model_path, method, device)\n",
    "\n",
    "    # Create class to create the embeddings for each layer\n",
    "    model2emb = Model2Embeddings(model, layers_to_save, flatten_output=True)\n",
    "\n",
    "    for split in ['test', 'train']:\n",
    "\n",
    "        output_dir = base_output_dir / method / dataset_name / split\n",
    "        \n",
    "        # Load dataset from GeoBench\n",
    "        dataset = GeobenchDataset(dataset_name=dataset_name, split=split, transform=None)\n",
    "\n",
    "        # Dataloader\n",
    "        batch_size = 10\n",
    "        dl = tdata.DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "        # loop over dataset and save embeddings with labels\n",
    "        for i, batch in tqdm(enumerate(dl), total=len(dl)):\n",
    "            data = batch[0]\n",
    "            labels = batch[1]\n",
    "\n",
    "            # Inference\n",
    "            d_embeddings = model2emb.forward_pass(data)\n",
    "\n",
    "            for j in range(batch_size):\n",
    "                idx = i*batch_size + j\n",
    "                for layer_name, embeddings in d_embeddings.items():\n",
    "                    embedding_layer = embeddings[j]\n",
    "                    fp_embeddings = output_dir / 'embeddings' / layer_name / f'{idx}.npy'\n",
    "                    fp_embeddings.parent.mkdir(parents=True, exist_ok=True)\n",
    "                    np.save(fp_embeddings, embedding_layer)\n",
    "\n",
    "                label = labels[j]\n",
    "                fp_labels = output_dir / 'labels' / f'{idx}.npy'\n",
    "                fp_labels.parent.mkdir(parents=True, exist_ok=True)\n",
    "                np.save(fp_labels, label.detach().cpu().numpy())\n",
    "\n",
    "        print(f'All embeddings saved for {split}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a64149f0-b080-497d-a46c-0b36518eea96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings for 6 layers with barlowtwins and m-bigearthnet.\n",
      "Using default backbone: resnet50\n",
      "Forward hooks registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:05<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All embeddings saved for test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [40:52<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All embeddings saved for train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "method = \"barlowtwins\"\n",
    "model_path = \"/work/data/weights/barlowtwins/100epochs.ckpt\"\n",
    "dataset_name = \"m-bigearthnet\"\n",
    "layers_to_save = [\n",
    "    'backbone.backbone.layer1.2.act3',\n",
    "    'backbone.backbone.layer2.3.act3',\n",
    "    'backbone.backbone.layer3.5.act3',\n",
    "    'backbone.backbone.layer4.0.act3',\n",
    "    'backbone.backbone.layer4.1.act3',\n",
    "    'backbone.backbone.layer4.2.act3',\n",
    "]\n",
    "base_output_dir = Path('/work/groupdrive/embeddings')\n",
    "d_embeddings = create_embeddings_geobench(model_path, method, dataset_name, layers_to_save, base_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71566cb7-a14e-43b2-a324-32b16d545035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSL4EO",
   "language": "python",
   "name": "ipy39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
